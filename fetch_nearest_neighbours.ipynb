{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_grid(images, shape=[10, 4], name='default', save=False):\n",
    "    \"\"\"\n",
    "    Plot images in a grid of a given shape.\n",
    "    Initial code from: https://github.com/pumpikano/tf-dann/blob/master/utils.py\n",
    "    \"\"\"\n",
    "    fig = plt.figure(1, figsize=(15, 6))\n",
    "    grid = ImageGrid(fig, 111, nrows_ncols=shape, axes_pad=0.05)\n",
    "\n",
    "    size = shape[0] * shape[1]\n",
    "    for i in range(size):\n",
    "        grid[i].axis('off')\n",
    "        grid[i].imshow(images[i], cmap='gray')  # The AxesGrid object work as a list of axes.\n",
    "    if save:\n",
    "        plt.savefig('./nn/' + str(name) + '.png', bbox_inches='tight', transparent = True , pad_inches = 0)\n",
    "        plt.clf()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = torch.load(\"./data/mnist/MNIST/processed/training.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_data[0].reshape(training_data[0].shape[0], training_data[0].shape[1]*training_data[0].shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = NearestNeighbors(n_neighbors=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=-1, n_neighbors=3, p=2, radius=1.0)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch for random sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change here for different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = torch.load(\"./mnist_004/mnist/mnistsamples.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_nn = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    sample = sampler[\"samples_\"+str(i)]\n",
    "    sample = np.array(sample)\n",
    "    \n",
    "    random_idx = np.random.randint(0, 2000)\n",
    "    random_sample = sample[random_idx]\n",
    "    images_nn.append(random_sample[0])\n",
    "    \n",
    "    random_sample = random_sample.reshape(28*28)\n",
    "    random_sample = ((random_sample - random_sample.min()) * (1/(random_sample.max() - random_sample.min()) * 255).astype('uint8'))\n",
    "    \n",
    "    nei = neigh.kneighbors(X=[random_sample] ,n_neighbors=3)\n",
    "    for i in nei[1][0]:\n",
    "        images_nn.append(training_data[0][i])\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow_grid(images_nn, name=\"005\", save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
